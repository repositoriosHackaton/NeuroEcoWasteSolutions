{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeman\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\jeman\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "#Cargar el modelo preentrenado\n",
    "modelo_base = load_model('cifar10.h5')\n",
    "\n",
    "#Congelar capas para conservar características\n",
    "for capa in modelo_base.layers[:-5]:\n",
    "    capa.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustar las últimas capas del modelo\n",
    "clases = 4\n",
    "\n",
    "x = modelo_base.layers[-2].output                                               #Conectar a la penúltima capa del modelo base\n",
    "x = Dense(256, activation='relu', name='custom_dense_stl10')(x)                 #Nombre único para la primera capa densa\n",
    "salida = Dense(clases, activation='softmax', name='custom_output_stl10')(x)     #Nombre único para la capa de salida\n",
    "modelo = Model(inputs=modelo_base.input, outputs=salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar datos desde el directorio\n",
    "ruta = '4Clases/'\n",
    "imagenes = []\n",
    "etiquetas = []\n",
    "\n",
    "#Recorrer las clases dentro del directorio principal\n",
    "for etiqueta in range(clases):\n",
    "    ruta_clase = os.path.join(ruta, f'class_{etiqueta}')\n",
    "    #Obtener lista de imágenes en cada clase\n",
    "    nombres_imagenes = os.listdir(ruta_clase)\n",
    "    #Completar las rutas de las imágenes\n",
    "    rutas_imagenes = [os.path.join(ruta_clase, nombre_imagen) for nombre_imagen in nombres_imagenes if nombre_imagen.endswith('.jpg')]\n",
    "    #Agregar a la lista de todas las imágenes y etiquetas\n",
    "    imagenes.extend(rutas_imagenes)\n",
    "    etiquetas.extend([etiqueta] * len(rutas_imagenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear conjuntos de datos\n",
    "tamano_lote = 32\n",
    "altura = 32\n",
    "ancho = 32\n",
    "\n",
    "imagenes_entrenamiento, imagenes_prueba, etiquetas_entrenamiento, etiquetas_prueba = train_test_split(\n",
    "    imagenes, etiquetas, test_size=0.3, random_state=123)\n",
    "\n",
    "imagenes_validacion, imagenes_prueba, etiquetas_validacion, etiquetas_prueba = train_test_split(\n",
    "    imagenes_prueba, etiquetas_prueba, test_size=0.5, random_state=123)\n",
    "\n",
    "#Procesamiento de imágenes\n",
    "def preprocess_image(ruta_imagen, etiqueta):\n",
    "    imagen = tf.io.read_file(ruta_imagen)\n",
    "    imagen = tf.image.decode_jpeg(imagen, channels=3)\n",
    "    imagen = tf.image.resize(imagen, size=(altura, ancho))\n",
    "    imagen = tf.cast(imagen, tf.float32) / 255.0  # Normalizar a [0,1]\n",
    "    return imagen, etiqueta\n",
    "\n",
    "#Crear datasets de entrenamiento, validación y prueba\n",
    "conjunto_entrenamiento = tf.data.Dataset.from_tensor_slices((imagenes_entrenamiento, etiquetas_entrenamiento))\n",
    "conjunto_entrenamiento = conjunto_entrenamiento.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "conjunto_entrenamiento = conjunto_entrenamiento.batch(tamano_lote).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "conjunto_validacion = tf.data.Dataset.from_tensor_slices((imagenes_validacion, etiquetas_validacion))\n",
    "conjunto_validacion = conjunto_validacion.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "conjunto_validacion = conjunto_validacion.batch(tamano_lote).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "conjunto_prueba = tf.data.Dataset.from_tensor_slices((imagenes_prueba, etiquetas_prueba))\n",
    "conjunto_prueba = conjunto_prueba.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "conjunto_prueba = conjunto_prueba.batch(tamano_lote).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "#Calcular la media y la desviación estándar de los datos de entrenamiento\n",
    "media = 0\n",
    "desviacion_estandar = 0\n",
    "cantidad_lotes = 0\n",
    "\n",
    "for imagenes, _ in conjunto_entrenamiento:\n",
    "    media_lote = tf.reduce_mean(imagenes, axis=[0, 1, 2])\n",
    "    desviacion_estandar_lote = tf.math.reduce_std(imagenes, axis=[0, 1, 2])\n",
    "    media += media_lote\n",
    "    desviacion_estandar += desviacion_estandar_lote\n",
    "    cantidad_lotes += 1\n",
    "\n",
    "media /= cantidad_lotes\n",
    "desviacion_estandar /= cantidad_lotes\n",
    "\n",
    "#Normalizar los datos usando z-score y codificar las etiquetas\n",
    "def normalize_and_encode_img(imagen, etiqueta):\n",
    "    imagen = (imagen - media) / (desviacion_estandar + 1e-7)\n",
    "    etiqueta = tf.one_hot(etiqueta, clases)\n",
    "    return imagen, etiqueta\n",
    "\n",
    "conjunto_entrenamiento = conjunto_entrenamiento.map(normalize_and_encode_img)\n",
    "conjunto_validacion = conjunto_validacion.map(normalize_and_encode_img)\n",
    "conjunto_prueba = conjunto_prueba.map(normalize_and_encode_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilar el modelo\n",
    "modelo.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Definir callbacks\n",
    "detencion_temprana = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduccion_tasa_aprendizaje = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "#Entrenar el modelo\n",
    "historial = modelo.fit(\n",
    "    conjunto_entrenamiento,\n",
    "    validation_data=conjunto_validacion,\n",
    "    epochs=100,\n",
    "    callbacks=[detencion_temprana, reduccion_tasa_aprendizaje]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluar el modelo\n",
    "perdida, precision = modelo.evaluate(conjunto_prueba)\n",
    "print(f\"Pérdida: {perdida}\")\n",
    "print(f\"Precisión: {precision}\")\n",
    "\n",
    "# Predicciones y etiquetas verdaderas para el conjunto de prueba\n",
    "probabilidades = modelo.predict(conjunto_prueba)\n",
    "predicciones = np.argmax(probabilidades, axis=1)\n",
    "valores_reales = np.concatenate([etiqueta for _, etiqueta in conjunto_prueba], axis=0)\n",
    "valores_reales = np.argmax(valores_reales, axis=1)  # Convertir y_true a su forma original\n",
    "\n",
    "# Calcular precisión global del nuevo modelo usando sklearn\n",
    "precision_global = accuracy_score(valores_reales, predicciones)\n",
    "print(\"Precisión global del nuevo modelo:\", precision_global)\n",
    "\n",
    "#Guardar el modelo entrenado\n",
    "modelo.save('modelo.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Modelo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
