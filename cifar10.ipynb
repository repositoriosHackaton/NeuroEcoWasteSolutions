{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importación de librerías\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar el dataset CIFAR-10\n",
    "(imagenes_entrenamiento, etiquetas_entrenamiento), (imagenes_prueba, etiquetas_prueba) = cifar10.load_data()\n",
    "print(\"Datos de entrenamiento: \", len(imagenes_entrenamiento))\n",
    "print(\"Datos de validación: \", len(imagenes_prueba))\n",
    "\n",
    "#Procesamiento de datos\n",
    "print(\"\\nValor original de pixel: \", imagenes_entrenamiento[0][0][0][0])\n",
    "media = np.mean(imagenes_entrenamiento, axis=(0, 1, 2, 3))\n",
    "desviacion_estandar = np.std(imagenes_entrenamiento, axis=(0, 1, 2, 3))\n",
    "imagenes_entrenamiento = (imagenes_entrenamiento - media) / (desviacion_estandar + 1e-7)\n",
    "imagenes_prueba = (imagenes_prueba - media) / (desviacion_estandar + 1e-7)\n",
    "print(\"Valor procesado de pixel: \", imagenes_entrenamiento[0][0][0][0])\n",
    "\n",
    "#Aumento de datos\n",
    "aumento_datos = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "aumento_datos.fit(imagenes_entrenamiento)\n",
    "\n",
    "#Convertir etiquetas a formato categórico\n",
    "clases = 10\n",
    "\n",
    "print(\"\\nEtiqueta original: \", etiquetas_entrenamiento[0][0])\n",
    "etiquetas_entrenamiento = tf.keras.utils.to_categorical(etiquetas_entrenamiento, clases)\n",
    "etiquetas_prueba = tf.keras.utils.to_categorical(etiquetas_prueba, clases)\n",
    "print(\"Etiqueta categórica: \", etiquetas_entrenamiento[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construcción del modelo\n",
    "modelo = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4), input_shape=imagenes_entrenamiento.shape[1:]),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(clases, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compilación del modelo\n",
    "modelo.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Configuración de callbacks\n",
    "detencion_temprana = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduccion_tasa_aprendizaje = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "#Entrenar el modelo\n",
    "tamano_lote = 64\n",
    "historial = modelo.fit(aumento_datos.flow(imagenes_entrenamiento, etiquetas_entrenamiento, batch_size=tamano_lote),\n",
    "                    steps_per_epoch=imagenes_entrenamiento.shape[0] // tamano_lote,\n",
    "                    epochs=5,\n",
    "                    validation_data=(imagenes_prueba, etiquetas_prueba),\n",
    "                    callbacks=[detencion_temprana, reduccion_tasa_aprendizaje])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluación del modelo\n",
    "perdida, precision = modelo.evaluate(imagenes_prueba, etiquetas_prueba)\n",
    "print(f\"Pérdida: {perdida}\")\n",
    "print(f\"Precisión: {precision}\")\n",
    "\n",
    "#Guardar el modelo entrenado\n",
    "modelo.save('cifar10.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Modelo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
